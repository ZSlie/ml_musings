{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23002c8",
   "metadata": {},
   "source": [
    "## This is to attempt a > 99.7% MNIST accuracy within Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63d359",
   "metadata": {},
   "source": [
    "The competition can be found [here](https://www.kaggle.com/competitions/digit-recognizer/overview).\n",
    "\n",
    "Inspired by the [MNIST pytorch example](https://github.com/pytorch/examples/blob/main/mnist/main.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507cd34",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61908c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0dfb8f",
   "metadata": {},
   "source": [
    "Define the net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919225a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c07830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_shape(h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n",
    "    from math import floor\n",
    "    if type(kernel_size) is not tuple:\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "    h = floor( ((h_w[0] + (2 * pad) - ( dilation * (kernel_size[0] - 1) ) - 1 )/ stride) + 1)\n",
    "    w = floor( ((h_w[1] + (2 * pad) - ( dilation * (kernel_size[1] - 1) ) - 1 )/ stride) + 1)\n",
    "    return h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b60369a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_output_shape((32, 64), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f313e2",
   "metadata": {},
   "source": [
    "Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9518490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe421e",
   "metadata": {},
   "source": [
    "Define the testing function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf5a1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa93024",
   "metadata": {},
   "source": [
    "Define the main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df527a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Training settings\n",
    "    print(\"Wtf.\")\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=21, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--no-mps', action='store_true', default=False,\n",
    "                        help='disables macOS GPU training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=True,\n",
    "                        help='For Saving the current Model')\n",
    "    print(\"Wtf.2\")\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    print(unknown)\n",
    "    print(args)\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "    print(\"Use CUDA: \", use_cuda)\n",
    "    print(\"Use MPS: \", use_mps)\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif use_mps:\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"../data/mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5b061",
   "metadata": {},
   "source": [
    "Use the generated conv net to predict the Kaggle csv test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be4dd8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([24, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).\n\tsize mismatch for conv1.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for conv2.weight: copying a param with shape torch.Size([20, 24, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for conv2.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([24, 2000]) from checkpoint, the shape in current model is torch.Size([128, 9216]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([10, 24]) from checkpoint, the shape in current model is torch.Size([10, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Net()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/mnist_cnn.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# set to evaluation mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Net:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([24, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).\n\tsize mismatch for conv1.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for conv2.weight: copying a param with shape torch.Size([20, 24, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for conv2.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([24, 2000]) from checkpoint, the shape in current model is torch.Size([128, 9216]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([10, 24]) from checkpoint, the shape in current model is torch.Size([10, 128])."
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('../data/mnist_cnn.pt'))\n",
    "model.eval()  # set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/test.csv')\n",
    "print(\"Test data length: \", len(data))\n",
    "images = torch.tensor(data.values, dtype=torch.float32)\n",
    "images = images.view(-1, 1, 28, 28)\n",
    "\n",
    "# Predict using loaded model\n",
    "with torch.no_grad():\n",
    "    predictions = model(images)\n",
    "    _, predicted_digits = torch.max(predictions, 1)  # get the class (digit) with highest probability\n",
    "\n",
    "print(len(predicted_digits))\n",
    "print(predicted_digits.numpy())\n",
    "predicted_df = pd.DataFrame(predicted_digits.numpy(), columns=['Label'])\n",
    "predicted_df.index += 1 \n",
    "#predicted_df['ImageId'] = predicted_df.index\n",
    "#print(predicted_df)\n",
    "predicted_df.to_csv('../data/predicted_digits.csv', index_label='ImageId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b947d",
   "metadata": {},
   "source": [
    "-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969df7c0",
   "metadata": {},
   "source": [
    "The following is an attempt to combine ensemble methods and transfer learning with the pytorch example. Inspired by [this kaggle notebook](https://www.kaggle.com/code/georgiisirotenko/pytorch-mnist-transferlearning-ensemble-99-714). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c2b69ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/typing_extensions-4.8.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/typing_extensions-4.8.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/numpy-1.26.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: seaborn in /opt/homebrew/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: pillow in /opt/homebrew/lib/python3.11/site-packages (10.0.1)\n",
      "Collecting tk\n",
      "  Downloading tk-0.1.0-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (1.25.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/typing_extensions-4.8.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/numpy-1.26.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tk\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/typing_extensions-4.8.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed tk-0.1.0\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/typing_extensions-4.8.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/typing_extensions-4.8.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/typing_extensions-4.8.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a751709",
   "metadata": {},
   "source": [
    "Note: you may need to install tk `brew install python-tk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790f1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88ed4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7de83520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "  def __init__(self, features, labels, Transform):\n",
    "    self.x = features\n",
    "    self.y = labels\n",
    "    self.transform = Transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.transform(self.x[index]), self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88907ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDf(df, Transform):\n",
    "  x_features = df.iloc[:, 1:].values\n",
    "  y_labels = df.label.values\n",
    "  x_features = x_features.reshape(-1, 1, 28, 28)\n",
    "  x_features = np.uint8(x_features)\n",
    "  x_features = torch.from_numpy(x_features)\n",
    "  y_labels = torch.from_numpy(y_labels)\n",
    "  return MyDataset(x_features, y_labels, Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae526685",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = {\n",
    " '0': transform.Compose([\n",
    "                           transform.ToPILImage(),\n",
    "                           transform.Resize(94),\n",
    "                           transform.Grayscale(num_output_channels=3), \n",
    "                           transform.ToTensor(),\n",
    "                           transform.Normalize(\n",
    "                                    [0.13097111880779266, 0.13097111880779266, 0.13097111880779266],\n",
    "                                    [0.30848443508148193, 0.30848443508148193, 0.30848443508148193])\n",
    "]),\n",
    "\n",
    "    '1': transform.Compose([\n",
    "                           transform.ToPILImage(),\n",
    "                           transform.Resize(94),\n",
    "                           transform.Grayscale(num_output_channels=3),\n",
    "                           transform.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                           transform.RandomRotation(5),\n",
    "                           transform.RandomAffine(degrees=11, translate=(0.1,0.1), scale=(0.8,0.8)),\n",
    "                           transform.ToTensor(),\n",
    "                           transform.Normalize(\n",
    "                                    [0.13097111880779266, 0.13097111880779266, 0.13097111880779266],\n",
    "                                    [0.30848443508148193, 0.30848443508148193, 0.30848443508148193])\n",
    "]),\n",
    "    'val': transform.Compose([\n",
    "                           transform.ToPILImage(),\n",
    "                           transform.Resize(94),\n",
    "                           transform.Grayscale(num_output_channels=3),\n",
    "                           transform.ToTensor(),\n",
    "                           transform.Normalize(\n",
    "                                  [0.13141274452209473, 0.13141274452209473, 0.13141274452209473],\n",
    "                                  [0.30904173851013184, 0.30904173851013184, 0.30904173851013184])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c71d0a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exampleset = GetDf(train_pd, Transform=transform.Compose([\n",
    "                           transform.ToPILImage(),\n",
    "                           transform.Grayscale(num_output_channels=3),\n",
    "                           transform.ToTensor()\n",
    "    ]))\n",
    "\n",
    "x, y = next(iter(torch.utils.data.DataLoader(exampleset)))\n",
    "\n",
    "channels = ['Red', 'Green', 'Blue']\n",
    "cmaps = [plt.cm.Reds_r, plt.cm.Greens_r, plt.cm.Blues_r]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 10))\n",
    "\n",
    "for i, axs in enumerate(fig.axes[:3]):\n",
    "    axs.imshow(x[0][i,:,:], cmap=cmaps[i])\n",
    "    axs.set_title(f'{channels[i]} Channel')\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "    \n",
    "ax[3].imshow(x[0].permute(1,2,0), cmap='gray')\n",
    "ax[3].set_title('Three Channels')\n",
    "ax[3].set_xticks([])\n",
    "ax[3].set_yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eabfd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, features,transform=transform.Compose([\n",
    "                              transform.ToPILImage(),\n",
    "        transform.Resize(94),\n",
    "        transform.Grayscale(num_output_channels=3),\n",
    "                              transform.ToTensor(),\n",
    "                              transform.Normalize(\n",
    "                                  [0.13141274452209473, 0.13141274452209473, 0.13141274452209473],\n",
    "                                  [0.30904173851013184, 0.30904173851013184, 0.30904173851013184])\n",
    "    ])):\n",
    "        self.features = features.values.reshape((-1,28,28)).astype(np.uint8)\n",
    "        self.targets = None\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.features[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a009731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(seed, test_size=0.1, df=train_pd, batch_size=50):\n",
    "    \n",
    "    # Create training set and validation set\n",
    "    train_data, valid_data = train_test_split(df,\n",
    "                                              test_size=test_size,\n",
    "                                              random_state=seed)\n",
    "    \n",
    "    # Create Datasets\n",
    "    train_dataset_0 = GetDf(train_data, Transform=transformer['0'])\n",
    "    train_dataset_1 = GetDf(train_data, Transform=transformer['1'])\n",
    "    \n",
    "    train_dataset = ConcatDataset([train_dataset_0, train_dataset_1])\n",
    "\n",
    "    valid_dataset = GetDf(valid_data, Transform=transformer['val'])\n",
    "    \n",
    "    # Create Dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "    train_size = len(train_dataset)\n",
    "    val_size = len(valid_dataset)\n",
    "\n",
    "    return train_loader, valid_loader, train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17f9bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'train':[], 'val':[]}\n",
    "accuracies = {'train':[], 'val':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1812f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seed, epochs, model):\n",
    "  \n",
    "  # Train and valid dataloaders\n",
    "  print('Creating new dataloaders...')\n",
    "    \n",
    "  train_loader, valid_loader, train_size, val_size = create_dataloaders(seed=seed)\n",
    "  \n",
    "  loaders = {'train': train_loader, 'val': valid_loader}\n",
    "  \n",
    "  dataset_sizes = {'train': train_size, 'val': val_size}\n",
    "  \n",
    "  print('Creating a model {}...'.format(seed))\n",
    "  # todo - ARGS\n",
    "  use_cuda = torch.cuda.is_available() # not args.no_cuda and\n",
    "  use_mps = torch.backends.mps.is_available() # not args.no_mps and\n",
    "  print(\"Use CUDA: \", use_cuda)\n",
    "  print(\"Use MPS: \", use_mps)\n",
    "  \n",
    "  # TODO: Seed\n",
    "  # torch.manual_seed(args.seed)\n",
    "  # TODO :: \n",
    "  #   if use_cuda:\n",
    "  #     device = torch.device(\"cuda\")\n",
    "  #   elif use_mps:\n",
    "  #     device = torch.device(\"mps\")\n",
    "  #   else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  \n",
    "  model.to(device)  \n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  if seed==2 or seed==3:\n",
    "    optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "  else:\n",
    "    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "  #   scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3, verbose=True)\n",
    "  \n",
    "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n",
    "  since = time.time()\n",
    "  best_model = copy.deepcopy(model.state_dict())\n",
    "  best_acc = 0.0\n",
    "  for epoch in range(epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "      else:\n",
    "        model.eval()\n",
    "      \n",
    "      running_loss = 0.0\n",
    "      running_corrects = 0.0\n",
    "  \n",
    "      for inputs, labels in loaders[phase]:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "  \n",
    "        with torch.set_grad_enabled(phase=='train'):\n",
    "          outp = model(inputs)\n",
    "          _, pred = torch.max(outp, 1)\n",
    "          loss = criterion(outp, labels)\n",
    "        \n",
    "          if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "  \n",
    "        running_loss += loss.item()*inputs.size(0)\n",
    "        running_corrects += torch.sum(pred == labels.data)\n",
    "  \n",
    "  #       if phase == 'train':\n",
    "  #           acc = 100. * running_corrects.double() / dataset_sizes[phase]\n",
    "  #           scheduler.step(acc)\n",
    "  \n",
    "      epoch_loss = running_loss / dataset_sizes[phase]\n",
    "      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
    "      losses[phase].append(epoch_loss)\n",
    "      accuracies[phase].append(epoch_acc)\n",
    "      if phase == 'train':\n",
    "        print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
    "      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n",
    "    \n",
    "      if phase == 'val':\n",
    "        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n",
    "        print('=='*31)\n",
    "      if phase == 'val' and epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    scheduler.step() \n",
    "  time_elapsed = time.time() - since\n",
    "  print('CLASSIFIER TRAINING TIME {}m {}s'.format(time_elapsed//60, time_elapsed%60))\n",
    "  print('=='*31)\n",
    "  \n",
    "  \n",
    "  model.load_state_dict(best_model)\n",
    "  \n",
    "  for param in model.parameters():\n",
    "        param.requires_grad=True\n",
    "  \n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)  \n",
    "  #   scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3, verbose=True)\n",
    "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n",
    "  for epoch in range(epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "      else:\n",
    "        model.eval()\n",
    "      \n",
    "      running_loss = 0.0\n",
    "      running_corrects = 0.0\n",
    "  \n",
    "      for inputs, labels in loaders[phase]:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "  \n",
    "        optimizer.zero_grad()\n",
    "  \n",
    "        with torch.set_grad_enabled(phase=='train'):\n",
    "          outp = model(inputs)\n",
    "          _, pred = torch.max(outp, 1)\n",
    "          loss = criterion(outp, labels)\n",
    "        \n",
    "          if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()*inputs.size(0)\n",
    "        running_corrects += torch.sum(pred == labels.data)\n",
    "  \n",
    "  #       if phase == 'train':\n",
    "  #         acc = 100. * running_corrects.double() / dataset_sizes[phase]\n",
    "  #         scheduler.step(acc)\n",
    "  \n",
    "      epoch_loss = running_loss / dataset_sizes[phase]\n",
    "      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
    "      losses[phase].append(epoch_loss)\n",
    "      accuracies[phase].append(epoch_acc)\n",
    "      if phase == 'train':\n",
    "        print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
    "      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n",
    "    \n",
    "      if phase == 'val':\n",
    "        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n",
    "        print('=='*31)    \n",
    "      if phase == 'val' and epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    scheduler.step() \n",
    "  time_elapsed = time.time() - since\n",
    "  print('ALL NET TRAINING TIME {}m {}s'.format(time_elapsed//60, time_elapsed%60))\n",
    "  print('=='*31)\n",
    "  \n",
    "  model.load_state_dict(best_model)\n",
    "    \n",
    "  model.eval() # Evaluation mode -> Turn off dropout\n",
    "  test_pred = torch.LongTensor()\n",
    "  \n",
    "  if use_cuda:\n",
    "    test_pred = test_pred.cuda()\n",
    "        \n",
    "  with torch.no_grad(): # Turn off gradients for prediction, saves memory and computations\n",
    "    for features in test_loader:\n",
    "        \n",
    "        if use_cuda:\n",
    "            features = features.cuda()\n",
    "  \n",
    "            # Get the softmax probabilities\n",
    "            outputs = model(features)\n",
    "            # Get the prediction of the batch\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            # Concatenate the prediction\n",
    "            test_pred = torch.cat((test_pred, predicted), dim=0)\n",
    "    \n",
    "  model_name = 'model_' + str(seed + 1)\n",
    "  ensemble_df[model_name] = test_pred.cpu().numpy()\n",
    "  print('Prediction Saved! \\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c670bb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /Users/z/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|█████████████████████████████████████| 30.8M/30.8M [00:04<00:00, 6.50MB/s]\n"
     ]
    }
   ],
   "source": [
    "densenet121_0 = torchvision.models.densenet121(pretrained=True)\n",
    "for param in densenet121_0.parameters():\n",
    "  param.requires_grad=False\n",
    "\n",
    "densenet121_0.classifier = nn.Linear(in_features=densenet121_0.classifier.in_features, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9999ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet121_1 = torchvision.models.densenet121(pretrained=True)\n",
    "for param in densenet121_1.parameters():\n",
    "  param.requires_grad=False\n",
    "\n",
    "densenet121_1.classifier = nn.Linear(in_features=densenet121_1.classifier.in_features, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bdedafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /Users/z/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
      "100%|█████████████████████████████████████| 49.7M/49.7M [00:07<00:00, 7.02MB/s]\n"
     ]
    }
   ],
   "source": [
    "googlenet = torchvision.models.googlenet(pretrained=True)\n",
    "for param in googlenet.parameters():\n",
    "  param.grad_requires = False\n",
    "\n",
    "googlenet.fc = nn.Linear(in_features=googlenet.fc.in_features, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c62189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /Users/z/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|███████████████████████████████████████| 171M/171M [00:26<00:00, 6.72MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet101 = torchvision.models.resnet101(pretrained=True)\n",
    "for param in resnet101.parameters():\n",
    "  param.grad_requires = False\n",
    "\n",
    "resnet101.fc = nn.Linear(in_features=resnet101.fc.in_features, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24647b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_bn = torchvision.models.vgg19_bn(pretrained=True)\n",
    "for param in vgg19_bn.parameters():\n",
    "  param.grad_requires = False\n",
    "\n",
    "vgg19_bn.classifier[6] = nn.Linear(4096, 10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38910566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new dataloaders...\n",
      "Creating a model 0...\n",
      "Use CUDA:  False\n",
      "Use MPS:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MyDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MyDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MyDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MyDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 36974) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:423\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 423\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 36974) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m models \u001b[38;5;241m=\u001b[39m [densenet121_0, densenet121_1, googlenet, resnet101, vgg19_bn]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_models):\n\u001b[0;32m---> 15\u001b[0m    \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 51\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(seed, epochs, model)\u001b[0m\n\u001b[1;32m     48\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     49\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m loaders[phase]:\n\u001b[1;32m     52\u001b[0m   inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     53\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1144\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 36974) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Create test_loader\n",
    "submit_df = pd.read_csv('../data/sample_submission.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "test_dataset = TestDataset(test_df)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "ensemble_df = submit_df.copy()\n",
    "\n",
    "num_models = 5\n",
    "num_epochs = 10\n",
    "\n",
    "models = [densenet121_0, densenet121_1, googlenet, resnet101, vgg19_bn]\n",
    "\n",
    "for seed in range(num_models):\n",
    "   train(seed=seed, epochs=num_epochs, model=models[seed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2a04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
